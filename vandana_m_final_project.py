# -*- coding: utf-8 -*-
"""VANDANA M Final_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13npPgx9OLYZJhTfZsW-4r9gsf0TQDRKA
"""

#import library
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
test=pd.read_csv("/content/test_2umaH9m.csv")
test

test.head()

test.tail()

test.info()

test.describe()

test.dtypes

test.shape

numerical=test.select_dtypes(include=['int64', 'float64']).columns.tolist()
categorical=test.select_dtypes(include=['object']).columns.tolist()
print("Numerical Columns:", numerical)
print("Categorical Columns:", categorical)

test[['department', 'region', 'education', 'gender', 'recruitment_channel']].value_counts()

import matplotlib.pyplot as plt
plt.figure(figsize=(15, 5))

plt.subplot(1, 3, 1)
sns.countplot(data=test, x='department')
plt.title('Distribution of department')
plt.xticks(rotation=45, ha='right')

plt.subplot(1, 3, 2)
sns.countplot(data=test, x='gender')
plt.title('Distribution of gender')
plt.xticks(rotation=45, ha='right')

plt.subplot(1, 3, 3)
sns.countplot(data=test, x='education')
plt.title('Distribution of education')
plt.xticks(rotation=45, ha='right')

plt.tight_layout()
plt.show()

#  correlation
numeric_test= test.select_dtypes(include=['number'])
display(numeric_test.corr())

test.isnull()

test.isnull().sum()

test['education'] = test['education'].fillna(test['education'].mode()[0])

test_mode = test.fillna(test.mode().iloc[0])
print("\nDataFrame after replacing NaN with mode:")
print(test_mode)

test.isnull().sum()

from sklearn.impute import SimpleImputer
#np.nan = NaN
imputer = SimpleImputer(missing_values=np.nan, strategy='mean')
imputer.fit(test[['previous_year_rating']])
test[['previous_year_rating']] = imputer.transform(test[['previous_year_rating']])
test

test.isnull().sum()

test.duplicated().sum()

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
test['department'] = le.fit_transform(test['department'])
test['region'] = le.fit_transform(test['region'])
test['education'] = le.fit_transform(test['education'])
test ['gender'] = le.fit_transform(test['gender'])
test['recruitment_channel'] = le.fit_transform(test['recruitment_channel'])
test

import matplotlib.pyplot as plt
sns.heatmap(test.corr(), annot=True)
plt.show()

sns.boxplot(test['education'])

sns.boxplot(test['previous_year_rating'])

from sklearn.preprocessing import StandardScaler
ssc = StandardScaler()
test[['employee_id']] = ssc.fit_transform(test[['employee_id']])
test

train=pd.read_csv("/content/train_LZdllcl.csv")
train

train.head()

train.tail()

train.info()

train.describe()

train.shape

train.dtypes

numerical=train.select_dtypes(include=['int64', 'float64']).columns.tolist()
categorical=train.select_dtypes(include=['object']).columns.tolist()
print("Numerical Columns:", numerical)
print("Categorical Columns:", categorical)

train[['department', 'region', 'education', 'gender', 'recruitment_channel']].value_counts()

import matplotlib.pyplot as plt
plt.figure(figsize=(15, 5))

plt.subplot(1, 3, 1)
sns.countplot(data=train, x='department')
plt.title('Distribution of department')
plt.xticks(rotation=45, ha='right')

plt.subplot(1, 3, 2)
sns.countplot(data=train, x='gender')
plt.title('Distribution of gender')
plt.xticks(rotation=45, ha='right')

plt.subplot(1, 3, 3)
sns.countplot(data=train, x='education')
plt.title('Distribution of education')
plt.xticks(rotation=45, ha='right')

plt.tight_layout()
plt.show()

#  correlation
numeric_train= train.select_dtypes(include=['number'])
display(numeric_train.corr())

train.isnull()

train.isnull().sum()

train['education'] = train['education'].fillna(train['education'].mode()[0])
train_mode = train.fillna(train.mode().iloc[0])
print("\nDataFrame after replacing NaN with mode:")
print(train_mode)

train.isnull().sum()

from sklearn.impute import SimpleImputer
#np.nan = NaN
imputer = SimpleImputer(missing_values=np.nan, strategy='mean')
imputer.fit(train[['previous_year_rating']])
train[['previous_year_rating']] = imputer.transform(train[['previous_year_rating']])
train

train.isnull().sum()

train.duplicated().sum()

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
train['department'] = le.fit_transform(train['department'])
train['region'] = le.fit_transform(train['region'])
train['education'] = le.fit_transform(train['education'])
train['gender'] = le.fit_transform(train['gender'])
train['recruitment_channel'] = le.fit_transform(train['recruitment_channel'])
train

import matplotlib.pyplot as plt
sns.heatmap(train.corr(), annot=True)
plt.show()

sns.boxplot(train['education'])

sns.boxplot(train['previous_year_rating'])

sns.boxplot(train['previous_year_rating'])

from sklearn.preprocessing import StandardScaler
ssc = StandardScaler()
train[['employee_id']] = ssc.fit_transform(train[['employee_id']])
train

"""MODELING AND TRAINING

"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
X = train.drop('is_promoted', axis=1)
y = train['is_promoted']
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
logreg = LogisticRegression(max_iter=1000)
logreg.fit(X_train, y_train)
val_preds = logreg.predict(X_val)
print("Accuracy:", accuracy_score(y_val, val_preds))
print("Classification Report:\n", classification_report(y_val, val_preds))
print("Confusion Matrix:\n", confusion_matrix(y_val, val_preds))

#Logistic Regression model
from sklearn.linear_model import LogisticRegression
lr = LogisticRegression()
lr.fit(X_train, y_train)

#kNN
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
val_preds = knn.predict(X_val)
print("Accuracy:", accuracy_score(y_val, val_preds))
print("Classification Report:\n", classification_report(y_val, val_preds))
print("Confusion Matrix:\n", confusion_matrix(y_val, val_preds))

#Decision Tree Classifier
from sklearn.tree import DecisionTreeClassifier
dtc = DecisionTreeClassifier()
dtc.fit(X_train, y_train)

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
dtree = DecisionTreeClassifier(random_state=42)
dtree.fit(X_train, y_train)
val_preds = dtree.predict(X_val)
print("Accuracy:", accuracy_score(y_val, val_preds))
print("Classification Report:\n", classification_report(y_val, val_preds))
print("Confusion Matrix:\n", confusion_matrix(y_val, val_preds))

#Random Forest
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(n_estimators=200)
rf.fit(X_train, y_train)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
rf_model = RandomForestClassifier(n_estimators=100,max_depth=None,random_state=42,n_jobs=-1)
rf_model.fit(X_train, y_train)
val_preds = rf_model.predict(X_val)
print("Validation Accuracy:", accuracy_score(y_val, val_preds))
print("Classification Report:\n", classification_report(y_val, val_preds))
print("Confusion Matrix:\n", confusion_matrix(y_val,val_preds))

#MLP classifier
from sklearn.neural_network import MLPClassifier
mlp = MLPClassifier(hidden_layer_sizes=(10,10,5), max_iter=1000, random_state=42)
mlp.fit(X_train, y_train)

from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
mlp = MLPClassifier(hidden_layer_sizes=(100, 50),max_iter=500,activation='relu',solver='adam',random_state=42)
mlp.fit(X_train, y_train)
val_preds = mlp.predict(X_val)
print("Validation Accuracy:", accuracy_score(y_val, val_preds))
print("Classification Report:\n", classification_report(y_val, val_preds))
print("Confusion Matrix:\n", confusion_matrix(y_val, val_preds))

# Model GNB
from sklearn.naive_bayes import GaussianNB
nb = GaussianNB()
nb.fit(X_train, y_train)

import pandas as pd
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report
model = GaussianNB()
model.fit(X_train, y_train)

y_pred_val = model.predict(X_val)
accuracy = accuracy_score(y_val, y_pred_val)
print(f"Validation Accuracy: {accuracy:.4f}")

print("\nClassification Report:")
print(classification_report(y_val, y_pred_val))

# GradientBoostingClassifier
from sklearn.ensemble import GradientBoostingClassifier
gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)
gb_clf.fit(X_train, y_train)

import pandas as pd
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report


# --- Train Gradient Boosting Classifier ---
model = GradientBoostingClassifier(random_state=42)
model.fit(X_train, y_train)

y_pred_val = model.predict(X_val)
accuracy = accuracy_score(y_val, y_pred_val)
print(f"Validation Accuracy: {accuracy:.4f}")
print("\nClassification Report:")
print(classification_report(y_val, y_pred_val))

#XGBClassifier
from xgboost import XGBClassifier
model = XGBClassifier(n_estimators=100,learning_rate=0.1,max_depth=3,eval_metric='mlogloss')
model.fit(X_train, y_train)

import pandas as pd
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report

model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)
model.fit(X_train, y_train)

y_pred_val = model.predict(X_val)
accuracy = accuracy_score(y_val, y_pred_val)
print(f"Validation Accuracy: {accuracy:.4f}")
print("\nClassification Report:")
print(classification_report(y_val, y_pred_val))

"""HYPERPARAMETER MANUAL TUING"""

#KNN with n_neighborsclassifier 3
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train, y_train)

knn.fit(X_train, y_train)
val_preds = knn.predict(X_val)
print("Accuracy:", accuracy_score(y_val, val_preds))

print("Classification Report:\n", classification_report(y_val, val_preds))

#KNN with n_neighborsclassifier 7
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=7)
knn.fit(X_train, y_train)

knn.fit(X_train, y_train)
val_preds = knn.predict(X_val)
print("Accuracy:", accuracy_score(y_val, val_preds))

print("Classification Report:\n", classification_report(y_val, val_preds))

#Random Forest n_estimators 150
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(n_estimators=150)
rf.fit(X_train, y_train)

rf_model.fit(X_train, y_train)
val_preds = rf_model.predict(X_val)
print("Validation Accuracy:", accuracy_score(y_val, val_preds))

print("Classification Report:\n", classification_report(y_val, val_preds))

#Random Forest n_estimators 100
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(n_estimators=100)
rf.fit(X_train, y_train)

rf_model.fit(X_train, y_train)
val_preds = rf_model.predict(X_val)
print("Validation Accuracy:", accuracy_score(y_val, val_preds))

print("Classification Report:\n", classification_report(y_val, val_preds))

#Random Forest n_estimators 50
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(n_estimators=50)
rf.fit(X_train, y_train)

rf_model.fit(X_train, y_train)
val_preds = rf_model.predict(X_val)
print("Validation Accuracy:", accuracy_score(y_val, val_preds))

print("Classification Report:\n", classification_report(y_val, val_preds))

# === Final Prediction and Export ===

# Store original employee IDs before they were standardized
test_original = pd.read_csv("/content/test_2umaH9m.csv")
employee_ids = test_original['employee_id']

# Apply label encoding to the test set
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
test['department'] = le.fit_transform(test['department'])
test['region'] = le.fit_transform(test['region'])
test['education'] = le.fit_transform(test['education'])
test ['gender'] = le.fit_transform(test['gender'])
test['recruitment_channel'] = le.fit_transform(test['recruitment_channel'])


# Use the trained model to predict on the test dataset
# Make sure to use the preprocessed `test` (not `test_original`)
predictions = model.predict(test)

# Create solution DataFrame
solution = pd.DataFrame({
    "employee_id": employee_ids,
    "is_promoted": predictions
})

# Save to CSV
solution.to_csv("solution.csv", index=False)
print("âœ… solution.csv generated successfully!")

from google.colab import files
files.download('/content/solution.csv')

